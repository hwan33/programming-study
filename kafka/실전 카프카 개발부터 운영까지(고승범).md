# 실전 카프카 개발부터 운영까지

저자 : 고승범

# 1장. 카프카 개요

생략

# 2장. 카프카 환경 구성

<details>
<summary>키 페어 생성 및 권한 변경</summary>
<br>
    
- 키페어의 생성은 클라우드 콘솔에서 생성 가능
- 아래 명령어를 이용해 키 페어 권한 변경 가능

```bash
chmod 600 keypair.pem
```
</details>

<details>
<summary>키 페어 이용해서 퍼블릭 IP 주소 접근</summary>
    <br>

- 아래 두 명령어 모두 가능

```bash
ssh -i keypair.pem -l ec2-user 13.125.209.60
ssh -i keypair.pem ec2-user@13.125.209.60
```
</details>

<details>
<summary>/etc/hosts 수정을 통한 서버 IP와 호스트네임 매핑</summary>
    <br>

- /etc/hosts 파일 예제
    - ip는 사설 ip
    - 모든 인스턴스에 설정

> 172.31.3.209 peter-ansible01.foo.bar peter-ansible01
> ... // 생략

- ping test 명령어

```bash
ping -c 2 peter-zk01.foo.bar
```
</details>

<details>
<summary>앤서블 설치 및 기타 환경 설정</summary>
    <br>

- 앤서블 설치
```bash
sudo amazon-linux-extras install -y ansible2
```

- git 설치 및 책에서 제공하는 git clone

```bash
sudo yum install -y git
git clone https://github.com/onlybooks/kafka2
```

- 키 페어 인스턴스에 복사
    - 로컬 terminal에서

```bash
scp -i keypair.pem keypair.pem ec2-user@13.125.20.117:~
```

- 권한 변경 및 키 등록

```bash
chmod 600 keypair.pem
ssh-agent bash
ssh-add keypair.pem
```

</details>

<details>
<summary>ssh 공개 키를 생성해 사용하는 방식</summary>
    <br>

- 키를 메모리에 저장해두고 사용하는 방식은 배포 서버 재접속때 설정이 초기화되는 문제 발생
- 아래와 같은 방식으로 ssh 공개 키를 생성해 사용하는 방식도 존재한다

1. 배포 서버에서 공개 키 생성
2. 공개 키 내용을 접속하고자 하는 서버에 복사
3. 배포 서버에서 다른 서버로 비밀번호 없이 접속

```bash
ssh-keygen // 이후 무한 엔터
cat /home/ec2-user/.ssh/id_rsa.pub // 확인 후 복사
```

- 이후 각각의 서버에 로그인하여 아래 명령어 실행

```bash
vi /home/ec2-user/.ssh/authorized_keys
chmod 600 .ssh/authorized_keys
```

</details>

<details>
<summary>주키퍼 설치</summary>
    <br>

- 앤서블 명령어인 ansible-playbook을 써서 hosts 파일에 지정된 zookeeper 서버에 모두 주키퍼를 설치

```bash
cd kafka2/chapter2/ansible_playbook
ansible-playbook -i hosts zookeeper.yml
```

- 각각의 주키퍼 서버에 접근해 제대로 실행되는지 확인

```bash
sudo systemctl status zookeeper-server
```

</details>

<details>
<summary>카프카 설치</summary>
    <br>

- 앤서블 명령어인 ansible-playbook을 써서 hosts 파일에 지정된 kafka 서버에 모두 카프카를 설치

```bash
cd kafka2/chapter2/ansible_playbook
ansible-playbook -i hosts kafka.yml
```

- 각각의 카프카 서버에 접근해 제대로 실행되는지 확인

```bash
sudo systemctl status kafka-server
```

</details>

<details>
<summary>토픽 생성</summary>
    <br>

- 카프카가 설치된 서버에 접속한 후 카프카에서 제공하는 도구 중 kafka-topics.sh 명령어를 이용해 토픽 생성

```bash
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01:9092 --create --topic peter-overview01 --partitions 1 --replication-factor 3
```

</details>

<details>
<summary>컨슈머, 프로듀서 실행 및 메세지 전달</summary>
    <br>

- 컨슈머 실행

```bash
/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server peter-kafka01:9092 --topic peter-overview01
```

- 프로듀서 실행

```bash
/usr/local/kafka/bin/kafka-console-producer.sh --bootstrap-server peter-kafka01:9092 --topic peter-overview01
```

- 메세지 전송
    - 프로듀서 실행 이후 명령 프롬포트가 `>`로 변경되면 메세지 입력
</details>

# 3장. 카프카 기본 개념과 구조

### 3.1) 카프카 기초 다지기

- 리플리케이션 : 각 메세지를 여러 개로 복제해서 카프카 클러스터 내 브로커들에 분산시키는 동작
    - 테스트나 개발 환경 : replication factor 1
    - 운영 환경 (로그성 메세지로서 약간의 유실 허용) : replication factor 2
    - 운영 환경 (유실 허용하지 않음) : replication factor 3

- 파티션 : 하나의 토픽이 한 번에 처리할 수 있는 한계를 높이기 위해 토픽 하나를 여러 개로 나눠 병렬 처리가 가능하게 만든 것
    - 파티션 수는 초기 생성 후 언제든지 늘릴 수 있지만, 한 번 늘린 파티션 수는 절대로 줄일 수 없음을 명심하자
    - 초기에는 2 또는 4로 생성하는 것을 추천

- 세그먼트 : 브로커의 로컬 디스크에 저장되는 로그 파일 형태

<details>
<summary>세그먼트 확인</summary>
    <br>

- 카프카가 설치된 서버에 접속

```bash
cd /data/kafka-logs/
ls
cd peter-overview01-0
ls
xxd 000000000000000000.log
```

</details>

### 3.2) 카프카의 핵심 개념

- 분산 시스템 : 시스템 확장에 용이
- 페이지 캐시 : 높은 처리량
- 배치 전송 처리 : 네트워크 오버헤드 감소
- 압축 전송 : 성능 향상
    - 배치 전송과 함께 사용 시 효율 증가
    - 높은 압축률이 필요한 경우 gzip, zstd
    - 빠른 응답 속도가 필요한 경우 lz4, snappy
- 토픽, 파티션, 오프셋
    - 토픽 : 이메일 주소의 개념
    - 파티션 : 토픽의 병렬 처리를 위한 단위
    - 오프셋 : 파티션의 메시지가 저장되는 위치
- 고가용성 보장
    - 카프카에서 제공하는 리플리케이션 기능은 토픽 자체를 복제하는 것이 아니라 토픽의 파티션을 복제
    - 원본과 리플리케이션을 구분하기 위해 leader와 follower라고 부른다
- 주키퍼의 의존성
    - 주키퍼는 여러 대의 서버를 앙상블(클러스터)로 구성하고, 살아 있는 노드 수가 과반수 이상 유지된다면 지속적인 서비스가 가능한 구조
    - 주키퍼는 반드시 홀수로 구성해야 한다

